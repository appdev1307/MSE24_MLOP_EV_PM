# ðŸ”„ Workflow Guide - Predictive Maintenance on Vehicle Telemetry Data

HÆ°á»›ng dáº«n chi tiáº¿t vá» workflow xá»­ lÃ½ tá»« data Ä‘áº¿n production model.

## ðŸ“‹ Tá»•ng Quan

**Äá» tÃ i**: Predictive Maintenance on Vehicle Telemetry Data

**Dataset**: [EVIoT Predictive Maintenance Dataset](https://www.kaggle.com/datasets/datasetengineer/eviot-predictivemaint-dataset/data)

**Workflow**:

```
Data (Kaggle)
  â†’ Processing Data
  â†’ Preparation
  â†’ Training
  â†’ Run Experiments (Models)
  â†’ Metrics/Params
  â†’ Select Best Model
  â†’ Register Version 1
  â†’ Production
```

## ðŸ—ï¸ Kiáº¿n TrÃºc Há»‡ Thá»‘ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATA INGESTION LAYER                         â”‚
â”‚                         (Kafka)                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  DATA PROCESSING LAYER                          â”‚
â”‚                      (Python)                                   â”‚
â”‚  - Preprocessing                                                â”‚
â”‚  - Feature Engineering                                          â”‚
â”‚  - Data Validation                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  DATA PREPARATION LAYER                         â”‚
â”‚                      (Python)                                   â”‚
â”‚  - Train/Test Split                                             â”‚
â”‚  - Data Normalization                                            â”‚
â”‚  - Feature Selection                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  MODEL TRAINING LAYER                           â”‚
â”‚              (XGBoost + MLflow)                                 â”‚
â”‚  - Train Multiple Models                                        â”‚
â”‚  - Hyperparameter Tuning                                        â”‚
â”‚  - Cross Validation                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  EXPERIMENT TRACKING                            â”‚
â”‚                      (MLflow)                                   â”‚
â”‚  - Log Metrics                                                   â”‚
â”‚  - Log Parameters                                               â”‚
â”‚  - Log Artifacts                                                 â”‚
â”‚  - Compare Experiments                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  MODEL SELECTION                                â”‚
â”‚                      (MLflow)                                   â”‚
â”‚  - Compare Metrics                                              â”‚
â”‚  - Select Best Model                                            â”‚
â”‚  - Register Version 1                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  MODEL REGISTRY                                 â”‚
â”‚                      (MLflow)                                   â”‚
â”‚  - Version Control                                               â”‚
â”‚  - Stage Management (Staging â†’ Production)                      â”‚
â”‚  - Artifact Storage (MinIO)                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PRODUCTION DEPLOYMENT                          â”‚
â”‚                    (FastAPI)                                    â”‚
â”‚  - Load Model from Registry                                     â”‚
â”‚  - Serve Inference API                                          â”‚
â”‚  - Monitoring (Prometheus + Grafana)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ”„ Chi Tiáº¿t Workflow

### Stage 1: Data Ingestion (Kafka)

**Má»¥c Ä‘Ã­ch**: Nháº­n dá»¯ liá»‡u telemetry tá»« vehicles real-time

**Components**:

- **Kafka**: Event streaming platform
- **Zookeeper**: Kafka coordination

**Workflow**:

```python
# Producer: Vehicle sensors â†’ Kafka
producer = KafkaProducer(bootstrap_servers='kafka:9092')
producer.send('vehicle-telemetry', json.dumps(telemetry_data))
```

**Setup**:

```bash
# Start Kafka services
docker compose up -d zookeeper kafka
```

**Output**: Raw telemetry data stream trong Kafka topics

---

### Stage 2: Data Processing (Python)

**Má»¥c Ä‘Ã­ch**: Xá»­ lÃ½ vÃ  lÃ m sáº¡ch dá»¯ liá»‡u

**Components**:

- **Python**: pandas, numpy
- **Scripts**: `src/preprocessing.py`

**Workflow**:

```python
# 1. Load data tá»« Kafka hoáº·c CSV
df = pd.read_csv("src/data/EV_Predictive_Maintenance_Dataset_15min.csv")

# 2. Data cleaning
df = df.dropna()
df = df.drop_duplicates()

# 3. Feature engineering
df['Battery_Health_Ratio'] = df['SoH'] / df['SoC']
df['Temperature_Diff'] = df['Battery_Temperature'] - df['Ambient_Temperature']

# 4. Data validation
assert df['SoC'].between(0, 1).all()
assert df['SoH'].between(0, 1).all()
```

**Script**: `src/preprocessing.py`

**Output**: Cleaned vÃ  processed dataset

---

### Stage 3: Data Preparation (Python)

**Má»¥c Ä‘Ã­ch**: Chuáº©n bá»‹ dá»¯ liá»‡u cho training

**Components**:

- **Python**: scikit-learn
- **Scripts**: `src/anomaly.py`, `src/classifier.py`, `src/rul.py`

**Workflow**:

```python
# 1. Feature selection
features = [
    'SoC', 'SoH', 'Battery_Voltage', 'Battery_Current',
    'Battery_Temperature', 'Motor_Temperature', ...
]

# 2. Train/Test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 3. Data normalization
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 4. Save preprocessing artifacts
joblib.dump(scaler, 'models/scaler.joblib')
joblib.dump(features, 'models/features.joblib')
```

**Output**: Prepared training data vÃ  preprocessing artifacts

---

### Stage 4: Training (XGBoost + MLflow)

**Má»¥c Ä‘Ã­ch**: Train multiple models vÃ  track experiments

**Components**:

- **XGBoost**: Gradient boosting models
- **LightGBM**: RUL prediction
- **Isolation Forest**: Anomaly detection
- **MLflow**: Experiment tracking

**Workflow**:

```python
import mlflow
import mlflow.xgboost
from xgboost import XGBClassifier

# 1. Start MLflow experiment
mlflow.set_experiment("predictive-maintenance")
mlflow.set_tracking_uri("http://mlflow:6969")

with mlflow.start_run(run_name="classifier-v1"):
    # 2. Train model
    model = XGBClassifier(
        n_estimators=100,
        max_depth=6,
        learning_rate=0.1
    )
    model.fit(X_train_scaled, y_train)

    # 3. Evaluate
    y_pred = model.predict(X_test_scaled)
    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='weighted')

    # 4. Log to MLflow
    mlflow.log_params({
        "n_estimators": 100,
        "max_depth": 6,
        "learning_rate": 0.1
    })

    mlflow.log_metrics({
        "accuracy": accuracy,
        "f1_score": f1
    })

    # 5. Log model
    mlflow.xgboost.log_model(model, "model")

    # 6. Log artifacts
    mlflow.log_artifacts("models/", "artifacts")
```

**Scripts**:

- `src/anomaly.py` - Train anomaly detection model
- `src/classifier.py` - Train fault classifier
- `src/rul.py` - Train RUL predictor
- `src/train_wrapper.py` - Orchestrate all training

**Run Training**:

```bash
# Local
python src/train_wrapper.py

# Docker
docker compose up trainer
```

**Output**: Trained models vÃ  MLflow experiments

---

### Stage 5: Run Experiments (Models)

**Má»¥c Ä‘Ã­ch**: Cháº¡y nhiá»u experiments vá»›i different hyperparameters

**Components**:

- **MLflow**: Track all experiments
- **Python**: Hyperparameter tuning

**Workflow**:

```python
# Experiment 1: Baseline
with mlflow.start_run(run_name="baseline"):
    model = XGBClassifier(n_estimators=50, max_depth=3)
    # ... train and log

# Experiment 2: Tuned hyperparameters
with mlflow.start_run(run_name="tuned-v1"):
    model = XGBClassifier(n_estimators=200, max_depth=6, learning_rate=0.05)
    # ... train and log

# Experiment 3: Different algorithm
with mlflow.start_run(run_name="lightgbm-v1"):
    from lightgbm import LGBMClassifier
    model = LGBMClassifier(n_estimators=150)
    # ... train and log
```

**View Experiments**:

```
http://localhost:6969
```

**Output**: Multiple experiment runs vá»›i different metrics

---

### Stage 6: Metrics/Params Analysis

**Má»¥c Ä‘Ã­ch**: PhÃ¢n tÃ­ch vÃ  so sÃ¡nh experiments

**Components**:

- **MLflow UI**: Visualize experiments
- **Python**: Compare metrics

**Workflow**:

```python
import mlflow
from mlflow.tracking import MlflowClient

client = MlflowClient()

# 1. Get all runs
experiment = client.get_experiment_by_name("predictive-maintenance")
runs = client.search_runs(experiment.experiment_id)

# 2. Compare metrics
for run in runs:
    print(f"Run: {run.info.run_name}")
    print(f"Accuracy: {run.data.metrics.get('accuracy', 'N/A')}")
    print(f"F1 Score: {run.data.metrics.get('f1_score', 'N/A')}")
    print("---")

# 3. Find best run
best_run = max(runs, key=lambda r: r.data.metrics.get('f1_score', 0))
print(f"Best run: {best_run.info.run_name}")
```

**MLflow UI**:

1. Má»Ÿ http://localhost:6969
2. VÃ o experiment "predictive-maintenance"
3. So sÃ¡nh metrics cá»§a cÃ¡c runs
4. Xem parameters vÃ  artifacts

**Output**: Best model Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh

---

### Stage 7: Select Best Model

**Má»¥c Ä‘Ã­ch**: Chá»n model tá»‘t nháº¥t dá»±a trÃªn metrics

**Components**:

- **MLflow**: Model comparison
- **Python**: Selection logic

**Workflow**:

```python
# Criteria for best model:
# 1. Highest F1 score
# 2. Good accuracy (> 0.85)
# 3. Low overfitting (train/test gap < 0.1)

best_run_id = "abc123def456"  # From Stage 6
best_model_uri = f"runs:/{best_run_id}/model"
```

**Manual Selection**:

1. VÃ o MLflow UI
2. So sÃ¡nh cÃ¡c runs
3. Chá»n run cÃ³ metrics tá»‘t nháº¥t
4. Copy run_id

**Output**: Best model URI

---

### Stage 8: Register Version 1

**Má»¥c Ä‘Ã­ch**: ÄÄƒng kÃ½ model vÃ o Model Registry

**Components**:

- **MLflow Model Registry**: Version control
- **MinIO**: Artifact storage

**Workflow**:

```python
import mlflow
from mlflow.tracking import MlflowClient

client = MlflowClient()

# 1. Register model
model_name = "ev-classifier"
model_version = client.create_model_version(
    name=model_name,
    source=f"runs:/{best_run_id}/model",
    run_id=best_run_id
)

print(f"Registered: {model_name} v{model_version.version}")

# 2. Add description
client.update_model_version(
    name=model_name,
    version=model_version.version,
    description="Best model from experiment v1 - F1: 0.92, Accuracy: 0.89"
)

# 3. Transition to Staging
client.transition_model_version_stage(
    name=model_name,
    version=model_version.version,
    stage="Staging"
)
```

**Via MLflow UI**:

1. VÃ o run details
2. Click "Register Model"
3. Táº¡o model name má»›i hoáº·c add vÃ o existing model
4. Model Ä‘Æ°á»£c register vá»›i version 1
5. Transition stage: None â†’ Staging â†’ Production

**Output**: Model registered vá»›i version 1 trong Staging

---

### Stage 9: Production Deployment

**Má»¥c Ä‘Ã­ch**: Deploy model vÃ o production

**Components**:

- **FastAPI**: Inference API
- **MLflow**: Load model from registry
- **Docker**: Containerization
- **Prometheus + Grafana**: Monitoring

**Workflow**:

```python
# inference_server.py
import mlflow
from mlflow.tracking import MlflowClient

# 1. Load model from registry
client = MlflowClient()
model_name = "ev-classifier"
model_version = client.get_latest_versions(
    model_name,
    stages=["Production"]
)[0]

model_uri = f"models:/{model_name}/Production"
model = mlflow.pyfunc.load_model(model_uri)

# 2. Serve with FastAPI
from fastapi import FastAPI
app = FastAPI()

@app.post("/predict")
def predict(data: dict):
    prediction = model.predict([data])
    return {"prediction": prediction[0]}
```

**Deploy**:

```bash
# Build vÃ  start inference service
docker compose build fastapi-inference
docker compose up -d fastapi-inference
```

**Monitor**:

- **Prometheus**: http://localhost:9090
- **Grafana**: http://localhost:3000
- **API Docs**: http://localhost:8000/docs

**Output**: Production API serving predictions

---

## ðŸ“Š Complete Workflow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Kaggle    â”‚
â”‚   Dataset   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Download
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Processingâ”‚  â† Python (pandas, numpy)
â”‚  - Cleaning     â”‚
â”‚  - Validation   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Preparation    â”‚  â† Python (scikit-learn)
â”‚  - Split        â”‚
â”‚  - Normalize    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Training     â”‚  â† XGBoost + MLflow
â”‚  - Train models â”‚
â”‚  - Experiments  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Experiments   â”‚  â† MLflow Tracking
â”‚  - Log metrics  â”‚
â”‚  - Log params   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Select Best    â”‚  â† MLflow UI
â”‚  - Compare      â”‚
â”‚  - Choose       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Register v1    â”‚  â† MLflow Registry
â”‚  - Version      â”‚
â”‚  - Stage        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Production    â”‚  â† FastAPI + Docker
â”‚  - Deploy       â”‚
â”‚  - Monitor      â”‚  â† Prometheus + Grafana
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸš€ Quick Start Commands

### 1. Download Dataset

```bash
# Script
bash scripts/download_dataset.sh
# hoáº·c
.\scripts\download_dataset.ps1
```

### 2. Process Data

```bash
python src/preprocessing.py
```

### 3. Train Models

```bash
# Local
python src/train_wrapper.py

# Docker
docker compose up trainer
```

### 4. View Experiments

```
http://localhost:6969
```

### 5. Register Best Model

```python
# Via Python script hoáº·c MLflow UI
```

### 6. Deploy to Production

```bash
docker compose up -d fastapi-inference
```

## ðŸ“ Best Practices

1. **Version Control**: LuÃ´n commit code trÆ°á»›c khi train
2. **Experiment Naming**: DÃ¹ng naming convention rÃµ rÃ ng
3. **Metrics Tracking**: Log Ä‘áº§y Ä‘á»§ metrics quan trá»ng
4. **Model Registry**: LuÃ´n register models trÆ°á»›c khi deploy
5. **Staging First**: Test model trong Staging trÆ°á»›c khi Production
6. **Monitoring**: Setup monitoring ngay sau khi deploy

## ðŸ”— Related Documentation

- [PROJECT_EXPLANATION.md](PROJECT_EXPLANATION.md) - Chi tiáº¿t vá» dá»± Ã¡n
- [USAGE_GUIDE.md](USAGE_GUIDE.md) - HÆ°á»›ng dáº«n sá»­ dá»¥ng
- [TECH_STACK.md](TECH_STACK.md) - Tech stack chi tiáº¿t

---

**LÆ°u Ã½**: Workflow nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c automate hoÃ n toÃ n qua GitHub Actions workflows.
