groups:
- name: ev-ml-inference-alerts
  rules:

  # ==========================================================
  # 1. Inference API Down (CRITICAL)
  # ==========================================================
  - alert: FastAPIInferenceDown
    expr: up{job="fastapi"} == 0
    for: 30s
    labels:
      severity: critical
    annotations:
      summary: "FastAPI inference service is down"
      description: "Prometheus cannot scrape fastapi-inference for 30 seconds."

  # ==========================================================
  # 2. High Inference Latency (WARNING)
  # ==========================================================
  - alert: HighInferenceLatency
    expr: |
      histogram_quantile(
        0.95,
        sum by (le) (
          rate(inference_request_latency_seconds_bucket{job="fastapi"}[3m])
        )
      ) > 0.5
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "High inference latency (p95 > 500ms)"
      description: "95th percentile inference latency exceeded 500ms for 2 minutes."

  # ==========================================================
  # 3. High Anomaly Rate (CRITICAL â€“ SAFETY)
  # ==========================================================
  - alert: HighAnomalyRate
    expr: |
      increase(anomaly_predictions_total[2m]) >= 5
    for: 15s
    labels:
      severity: critical
    annotations:
      summary: "High anomaly prediction volume"
      description: "5 or more anomaly predictions in the last 2 minutes."

  # ==========================================================
  # 4. No Traffic (INFO)
  # ==========================================================
  - alert: NoInferenceTraffic
    expr: |
      increase(inference_requests_total[5m]) == 0
    for: 5m
    labels:
      severity: info
    annotations:
      summary: "No inference traffic"
      description: "No inference requests received in the last 5 minutes."
